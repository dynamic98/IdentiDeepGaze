{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from loadData import *\n",
    "from ML_util import *\n",
    "from Dataset import IdentiGazeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Similar_All.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 400\n",
    "batch_size = 32\n",
    "train_vaild_Dataset = IdentiGazeDataset(path, 'train')\n",
    "testDataset = IdentiGazeDataset(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(train_vaild_Dataset)*0.8)\n",
    "valid_size = len(train_vaild_Dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(train_vaild_Dataset, [train_size, valid_size])\n",
    "\n",
    "test_size = len(testDataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Example Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=self.padding, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        return x[:, :, :-self.padding]  # Remove the padding on the right\n",
    "\n",
    "class GatedActivationUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super(GatedActivationUnit, self).__init__()\n",
    "        self.conv = CausalConv1d(in_channels, out_channels * 2, kernel_size, stride, dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        out, gate = x.chunk(2, dim=1)  # Split the tensor along the channel dimension\n",
    "        return torch.tanh(out) * torch.sigmoid(gate)  # Gated activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentiGazeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentiGazeNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        # Define the output layer\n",
    "        self.output = nn.Linear(128, 34)\n",
    "\n",
    "        self.RawGazeNet = nn.Sequential(\n",
    "            # Input Size: (84,2)\n",
    "            CausalConv1d(2, 4, kernel_size=7, stride=1, dilation=2),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3),\n",
    "            CausalConv1d(4, 5, kernel_size=5, stride=1, dilation=4),\n",
    "            CausalConv1d(5, 16, kernel_size=3, stride=1, dilation=5),\n",
    "            CausalConv1d(16, 32, kernel_size=3, stride=1, dilation=16),\n",
    "            nn.AdaptiveMaxPool1d(1),  # Global Max Pooling\n",
    "        )\n",
    "\n",
    "        self.EyeMovementNet = nn.Sequential(\n",
    "            nn.Linear(9, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 34)\n",
    "        )\n",
    "\n",
    "        self.FixationNet = nn.Sequential(\n",
    "            nn.Linear(10, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 34)\n",
    "        )\n",
    "\n",
    "        self.SaccadeNet = nn.Sequential(\n",
    "            nn.Linear(17, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 34)\n",
    "        )\n",
    "\n",
    "        self.MFCCNet = nn.Sequential(\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 34)\n",
    "        )\n",
    "\n",
    "        self.PupilNet = nn.Sequential(\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 34)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, rawgaze, eyemovement, fixation, saccade, mfcc, pupil):\n",
    "        # Apply the gated convolutions\n",
    "        rawgaze = self.RawGazeNet(rawgaze)\n",
    "        rawgaze = rawgaze.view(rawgaze.size(0), -1)\n",
    "        rawgaze = F.relu(self.fc1(rawgaze))\n",
    "        rawgaze = self.dropout(rawgaze)\n",
    "        rawgaze = F.relu(self.fc2(rawgaze))\n",
    "        rawgaze = self.output(rawgaze)\n",
    "\n",
    "        eyemovement = eyemovement.view(eyemovement.size(0), -1)\n",
    "        eyemovement = self.EyeMovementNet(eyemovement)\n",
    "        fixation = self.FixationNet(fixation)\n",
    "        saccade = self.SaccadeNet(saccade)\n",
    "        mfcc = self.MFCCNet(mfcc)\n",
    "        pupil = self.PupilNet(pupil)\n",
    "\n",
    "        out = rawgaze + eyemovement + fixation + saccade + mfcc + pupil\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 34])\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter('/runs')\n",
    "idModel = IdentiGazeNet()\n",
    "output = idModel(torch.randn(1,2,84).to(device), torch.randn(1,9).to(device),torch.randn(1,10).to(device),torch.randn(1,17).to(device),torch.randn(1,12).to(device),torch.randn(1,12).to(device))\n",
    "# print(len(myIdentiGaze))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(idModel.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scilab\\Desktop\\논문\\Identigaze Implicit reference\\identigaze2\\python\\Dataset.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  eyemovement = torch.FloatTensor(self.eyemovement.iloc[index])\n",
      "c:\\Users\\scilab\\Desktop\\논문\\Identigaze Implicit reference\\identigaze2\\python\\Dataset.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  fixation = torch.FloatTensor(self.fixation.iloc[index])\n",
      "c:\\Users\\scilab\\Desktop\\논문\\Identigaze Implicit reference\\identigaze2\\python\\Dataset.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  saccade = torch.FloatTensor(self.saccade.iloc[index])\n",
      "c:\\Users\\scilab\\Desktop\\논문\\Identigaze Implicit reference\\identigaze2\\python\\Dataset.py:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mfcc = torch.FloatTensor(self.MFCC.iloc[index])\n",
      "c:\\Users\\scilab\\Desktop\\논문\\Identigaze Implicit reference\\identigaze2\\python\\Dataset.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pupil = torch.FloatTensor(self.pupil.iloc[index])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m idModel(rawgaze, eyemovement, fixation, saccade, mfcc, pupil)\n\u001b[1;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m     18\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        rawgaze = data['rawgaze'].to(device).type(dtype=torch.float32)\n",
    "        eyemovement = data['eyemovement'].to(device).type(dtype=torch.float32)\n",
    "        fixation = data['fixation'].to(device).type(dtype=torch.float32)\n",
    "        saccade = data['saccade'].to(device).type(dtype=torch.float32)\n",
    "        mfcc = data['mfcc'].to(device).type(dtype=torch.float32)\n",
    "        pupil = data['pupil'].to(device).type(dtype=torch.float32)\n",
    "        y = data['y'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = idModel(rawgaze, eyemovement, fixation, saccade, mfcc, pupil)\n",
    "        loss = criterion(outputs, y)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    Accuracy = 100 * correct // total\n",
    "    # Tensorboard 사용하려면 아래 주석 해제\n",
    "    # writer.add_scalar('Acc/train', Accuracy, epoch+1)\n",
    "    # writer.add_scalar('Loss/train', running_loss, epoch+1)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            rawgaze = data['rawgaze'].to(device).type(dtype=torch.float32)\n",
    "            eyemovement = data['eyemovement'].to(device).type(dtype=torch.float32)\n",
    "            fixation = data['fixation'].to(device).type(dtype=torch.float32)\n",
    "            saccade = data['saccade'].to(device).type(dtype=torch.float32)\n",
    "            mfcc = data['mfcc'].to(device).type(dtype=torch.float32)\n",
    "            pupil = data['pupil'].to(device).type(dtype=torch.float32)\n",
    "            y = data['y'].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = idModel(rawgaze, eyemovement, fixation, saccade, mfcc, pupil)\n",
    "            test_loss = criterion(outputs, y)\n",
    "\n",
    "            # Tensorboard 사용하려면 아래 주석 해제\n",
    "            # writer.add_scalar('Loss/valid', test_loss, epoch+1)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "        Accuracy = 100 * correct // total\n",
    "        print(f'Accuracy of the network on the 10000 test images: {Accuracy} %')\n",
    "        # Tensorboard 사용하려면 아래 주석 해제\n",
    "        # writer.add_scalar('Acc/valid', Accuracy, epoch+1)\n",
    "\n",
    "        # 모델 저장하고싶으면 아래 주석 해제\n",
    "        # torch.save(idModel.state_dict(), f'model/IdNet3/{epoch}_{100 * correct // total}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siameseNetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
